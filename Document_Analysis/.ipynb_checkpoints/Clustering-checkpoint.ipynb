{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sESw_dKQL5mA"
   },
   "source": [
    "# nltkの文章群にscikit-learnを用いてクラスタリングを適用してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nFpmxQOMIKS"
   },
   "source": [
    "## 導入編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFmxTSs2MV2y"
   },
   "source": [
    "### 必要なライブラリ・データセットのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v9v_nPKQMTZd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-14e1594d9cd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2UGMZJaMgvM"
   },
   "source": [
    "### 今回は以下のnltkの機能を使用できる様にする\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaRmXeotMjKv",
    "outputId": "19770bdc-2cb6-4153-abf5-5ba9ca181408"
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"reuters\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VtrTuH4MrHN"
   },
   "source": [
    "### データを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXcN4x3bMljo"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters as corpus\n",
    "\n",
    "#!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6PFfk-BMxEs"
   },
   "source": [
    "### datasetの中身を確認。場合によって、次のようなコードを実行する必要があります。\n",
    "\"!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXvSxPG0MuXr",
    "outputId": "e6da887e-9841-427e-ca83-f0b51048b36b"
   },
   "outputs": [],
   "source": [
    "for n,item in enumerate(corpus.words(corpus.fileids()[0])[:300]):\n",
    "    print(item, end=\" \")\n",
    "    if (n%25) ==24:\n",
    "      print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lysFJt4M1Ux"
   },
   "source": [
    "### 全document数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Yz5UaciM0UG",
    "outputId": "cef75e41-0b29-4a9c-d42d-7bc7a22bd368"
   },
   "outputs": [],
   "source": [
    "len(corpus.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eu_yYroqM8-8"
   },
   "source": [
    "### (例) 前からk個のdocumentのみで学習する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOSFXIzlM5wI"
   },
   "outputs": [],
   "source": [
    "# k = 100\n",
    "#docs=[corpus.words(fileid) for fileid in corpus.fileids()[:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiXa4ySJNBDC"
   },
   "source": [
    "### 全documentで学習する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyNbkvs9NAav",
    "outputId": "0631022a-42da-4fe9-ed7f-52bfba0c5df4"
   },
   "outputs": [],
   "source": [
    "docs=[corpus.words(fileid) for fileid in corpus.fileids()]\n",
    "\n",
    "print(docs[:5])\n",
    "print(\"num of docs:\", len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U17VbjPaNIAD"
   },
   "source": [
    "## 前処理編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGPSmgSNNMFs"
   },
   "source": [
    "### 例 : ストップワードリストの作成\n",
    "\n",
    "### nltkのストップワードリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHC1l7zDNFLx"
   },
   "outputs": [],
   "source": [
    "en_stop = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqdBEQpUNT74"
   },
   "source": [
    "### 例:【発展】記号や数字は正規表現で消してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to0DASSYNRj0"
   },
   "outputs": [],
   "source": [
    "en_stop= [\"``\",\"/\",\",.\",\".,\",\";\",\"--\",\":\",\")\",\"(\",'\"','&',\"'\",'),',',\"','-','.,','.,\"','.-',\"?\",\">\",\"<\"]                  \\\n",
    "         +[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"86\",\"1986\",\"1987\",\"000\"]                                                      \\\n",
    "         +[\"said\",\"say\",\"u\",\"v\",\"mln\",\"ct\",\"net\",\"dlrs\",\"tonne\",\"pct\",\"shr\",\"nil\",\"company\",\"lt\",\"share\",\"year\",\"billion\",\"price\"]          \\\n",
    "         +en_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hdG75XqNYPa"
   },
   "source": [
    "### 前処理関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1jUH0P-NcoP"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn #lemmatize関数のためのimport\n",
    "\n",
    "def preprocess_word(word, stopwordset):\n",
    "    \n",
    "    #1.make words lower ex: Python =>python\n",
    "    word=word.lower()\n",
    "    \n",
    "    #2.remove \",\" and \".\"\n",
    "    if word in [\",\",\".\"]:\n",
    "        return None\n",
    "    \n",
    "    #3.remove stopword  ex: the => (None) \n",
    "    if word in stopwordset:\n",
    "        return None\n",
    "    \n",
    "    #4.lemmatize  ex: cooked=>cook\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "\n",
    "    elif lemma in stopwordset: #lemmatizeしたものがstopwordである可能性がある\n",
    "        return None\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "\n",
    "def preprocess_document(document):\n",
    "    document=[preprocess_word(w, en_stop) for w in document]\n",
    "    document=[w for w in document if w is not None]\n",
    "    return document\n",
    "\n",
    "def preprocess_documents(documents):\n",
    "    return [preprocess_document(document) for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJZeCVgNNi5T"
   },
   "source": [
    "### 前処理の結果を出力してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGX6YzgVNmbV"
   },
   "source": [
    "### 前処理前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u2P8lmTNgLn",
    "outputId": "d0072517-3e8b-4780-cdd9-ab9ec1e2f03b"
   },
   "outputs": [],
   "source": [
    "print(docs[0][:25]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki-UHTcXNptm"
   },
   "source": [
    "### 前処理後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rHr8yGINpDM",
    "outputId": "ced83e32-5494-4a68-ac9b-4d5f32593694"
   },
   "outputs": [],
   "source": [
    "print(preprocess_documents(docs)[0][:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIwd7wGvNyWj"
   },
   "source": [
    "## クラスタリング編"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPAMVMFaN2yL"
   },
   "source": [
    "### tf idfで上記の前処理済みの文章をベクトル化\n",
    "### vectorizerを使用する（ハイパーパラメーターの設定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVtbDMmtNuQV",
    "outputId": "ae97d3c0-7906-4fc8-e241-4b36f1ed09a3"
   },
   "outputs": [],
   "source": [
    "pre_docs=preprocess_documents(docs)\n",
    "pre_docs=[\" \".join(doc) for doc in pre_docs]\n",
    "print(pre_docs[0])\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=200, token_pattern=u'(?u)\\\\b\\\\w+\\\\b' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOOrgZHZN_Aw"
   },
   "source": [
    "### fitする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98b3XjG7N8nZ"
   },
   "outputs": [],
   "source": [
    "tf_idf = vectorizer.fit_transform(pre_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKhgoWLeOCW_"
   },
   "source": [
    "### K-means\n",
    "### kmeansの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVRkE4lsOBuL"
   },
   "outputs": [],
   "source": [
    "num_clusters = 8\n",
    "km = KMeans(n_clusters=num_clusters, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoOo2YWkOU9T"
   },
   "source": [
    "### fitする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmhVNkcyOSxq"
   },
   "outputs": [],
   "source": [
    "clusters = km.fit_predict(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIcN2sKSOZdu"
   },
   "source": [
    "### 出力結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBFqXETzOXec"
   },
   "outputs": [],
   "source": [
    "for doc, cls in zip(pre_docs, clusters):\n",
    "    print(cls,doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRRWSoojOm1-"
   },
   "source": [
    "## 応用\n",
    "クラスタリング編でコードを以下に指示に従って変更する事で結果がどの様に変わるのかを確認してみましょう．<br>\n",
    "    （１）講義で学んだ他の手法でベクトル化してみる(例：bag-of-words)<br>\n",
    "    （２）kmeans以外の手法、又はkmeansを可視化してみる(例：階層型クラスタリング)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ps1PgVeyOfbU"
   },
   "source": [
    "## ヒント\n",
    "\n",
    "scikit-learnのvectorizerとkmeansにはたくさんのハイパーパラメータがあります。vectorizerのハイパーパラメータの中には前処理機能(例：stop_words)もあります。\n",
    "    ハイパーパラメータの設定を変える事で最終的な結果は変わります。以下のURLにアクセスしてハイパーパラメータの独自で設定してみてください。<br>\n",
    "    ・TF-IDFに関するパラメータ<br>\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html<br>\n",
    "    ・Kmeansに関するパラメータ<br>\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html<br>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb のコピー",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
