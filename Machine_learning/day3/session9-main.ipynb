{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with neural networks / ニューラルネットワークによる分類 (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief introduction on artificial neural networks / 人口ニューラルネットの概要\n",
    "\n",
    "The picture bellow shows a biological neuron (top) and an artifical neuron (bottom)\n",
    "\n",
    "下の写真は、生物学的のニューロン(神経細胞；上）と人工ニューロン（下）を示しています。\n",
    "\n",
    "<br>\n",
    "<img src=\"./img/neurons.jpg\" width=\"400\">\n",
    "<br>\n",
    "\n",
    "The artificial neuron is a very simplified model of the biological neuron.\n",
    "- The \"inputs\" of the artificial neuron act like the dendrites of the biological neurons. They take in the signals from neighbouring neurons.\n",
    "- The \"output\" of the artificial neuron act like the axon of the biological neurons. They forward the signal to other the inputs of other neurons.\n",
    "- The artificial neuron computes a weighted sum of the inputs, and outputs a nonlinear function of that sum.\n",
    "<br><br>\n",
    "\n",
    "人工ニューロンは、生物学的ニューロンの非常に単純化されたモデルである。\n",
    "- 人工ニューロンの「入力」は、生物学的ニューロンの樹状突起のように機能します。隣接するニューロンからの信号を取り込みます。\n",
    "- 人工ニューロンの「出力」は、生物学的ニューロンの軸索のように働き、他のニューロンの入力に信号を送ります。\n",
    "- 人工ニューロンは、入力の加重和を計算し、その和の非線形関数を出力します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, the operation of one artificial neuron can be written with the following equation.\n",
    "\n",
    "数学的には、1つの人工ニューロンの動作は次の式で書くことができます。\n",
    "\n",
    "$\\mathbf{Y} = f(\\mathbf{W} \\mathbf{X})$\n",
    "\n",
    "- $\\mathbf{X} = [1, x_1, ..., x_n]^{T}$ is a vector containing all the inputs (plus the number 1).\n",
    "\n",
    "- The input multiplication factors ($\\mathbf{W} = [w_0, w_1, ..., w_n]$) are referred to as the __weights__ and the function $f$ the __activation__. The activation function is typicaly a nonlinear function.<br>\n",
    "\n",
    "- $\\mathbf{Y} = [y_1, ..., y_m]^{T}$ is a vector of all the neuron outputs.<br>\n",
    "\n",
    "\n",
    "- $\\mathbf{X} = [1, x_1, ..., x_n]^{T}$ は、すべての入力（および 1）を含むベクトルです。\n",
    "\n",
    "- 入力の加重$\\mathbf{W}$は__重み__と呼ばれ、関数$f$は__活性化関数__と呼ばれます。$f$は通常、非線形関数です。\n",
    "\n",
    "- $\\mathbf{Y} = [y_1, ..., y_m]^{T}$ は、ニューロンの出力を含むベクトルです。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation done by a single artificial neuron us very simple.  Like biological neurons, the \"strength\" of artificial neuron is the result of combining many neurons in a network. The resulting structure is called an __artificial neural network__ (ANN) or often simply a __neural network__ (NN).\n",
    "\n",
    "1つの人工ニューロンが行う計算は非常に単純です。生物学的ニューロンと同様に、人工ニューロンの「強み」は、多数のニューロンを組み合わせてネットワークにすることから生じる。得られた構造は__人工ニューラルネットワーク__（人工神経網）と呼ばれます。省略して__ニューラルネットワーク__と呼ばれることがよくあります。\n",
    "\n",
    "<img src=\"./img/network.jpg\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neurons are typically organized in __layers__. Neurons in each layer take as inputs the outputs from the neurons in the previous layer. \n",
    "<br>\n",
    "The inputs to the neural network are usually called the first layer or the _input layer_, the last layer in the network is called the _output layer_, and the layers inbetween are referred to as _hidden layers_.\n",
    "\n",
    "ニューロンは通常、__層__に分かれています。各層のニューロンは、前の層のニューロンの出力を入力として受け取ります。\n",
    "<br>\n",
    "ニューラルネットワークの入力は、通常、第1層または _入力層_ と呼ばれ、ネットワークの最後の層は _出力層_ と呼ばれ、その間の層は _隠れ層_ （中間層）と呼ばれます。\n",
    "\n",
    "<img src=\"./img/nn_layers.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the diagram above, a neuron is usually connected to _all_ neurons in the previous layer. Such neural network is called the __fully-connected neural network__ (FCNN). This is the type which we study in this session.\n",
    "\n",
    "上の図のように、ニューロンは通常、前の層の _すべて_ のニューロンに接続されています。このようなニューラルネットワークは、__全結合ニューラルネットワーク__ と呼ばれます。このセッションでは、このタイプのニューラルネットワークを勉強します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Deep neural networks and deep learning_<br> \n",
    "> Artifical neural networks have been studied for a long time. However, using neural networks with more than just 3 or 4 layers became possible only very recently. Networks with many layers are \"deep\", which is why they have been called __deep neural networks__ (DNN), and the use of DNNs for machine learning is referred to as __deep learning__ (DL). Having many layers have gives DNNs a much better capacity for learning from data, which is why there have been a huge number of very succesful applications of deep learning in recent years.\n",
    "\n",
    "> _ディープニューラルネットワークと深層学習_ <br>\n",
    "人工ニューラルネットワークの研究は古くから行われてきました。しかし、層数の多いニューラルネットワークの利用が可能になったのはごく最近のことです。層数の多いネットワークは「深い」ことから、__ディープニューラルネットワーク__（DNN）または _深層ネットワーク_ と呼ばれます。DNNを用いた機械学習は __深層学習__ または _ディープラーニング_ （DL）と呼ばれています。層が多いことでデータからの学習能力が格段に向上するため、近年では深層学習の応用例が非常に多くなっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will see how to build artificial neural networks and use them for classifying the digit of the MNIST dataset and the flowers of the iris dataset.\n",
    "\n",
    "このセッションでは、人工ニューラルネットワークを構築し、MNISTデータセットやアヤメのデータセットを分類することを使用する方法について説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the tools / ツールの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us import the usual packages.\n",
    "\n",
    "まず、必要なパッケージをインポートしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import packages for using neural networks. `tensorflow` is a library for using neural networks that also makes possible to perform computations on the GPU to accelerate the computing.\n",
    "\n",
    "ニューラルネットワークを使用するためのパッケージをインポートしましょう。 `tensorflow`はニューラルネットワークを利用するためのライブラリで、計算を高速化するためにGPUでの計算も可能にしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will not `tensorflow` directly. Instead we will use a frontend library called `keras`, which gives a simpler way of building and training neural networks.\n",
    "<br>\n",
    "The lines below import all the building blocks for the networks that we will create in this session.\n",
    "\n",
    "ここでは、`tensorflow`を直接使用しません。代わりに、ニューラルネットワークの構築とトレーニングをよりシンプルに行うことができる、`keras`というフロントエンドライブラリを使用します。\n",
    "<br>\n",
    "以下の行は、このセッションで作成するネットワークのすべての構成要素をインポートしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST dataset / MNISTデータセットを読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we load the full MNIST dataset (70000 samples).\n",
    "\n",
    "先週のセッションと違って、今回はMNISTデータセットの全体（70000サンプル）をロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mnist_loader import MNISTVectorLoader\n",
    "# 43 is used to initialize the random generator in the object\n",
    "mnist_vector_loader = MNISTVectorLoader(43)\n",
    "X, y = mnist_vector_loader.samples(70000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset between training and testing sets.\n",
    "\n",
    "データセットをトレーニング用のセットとテスト用のセットに分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 35000\n",
      "Testing set size: 35000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Testing set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply standardization.\n",
    "\n",
    "標準化を適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a fully connected network / 全結合ネットワークを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us define the input layer of the network using the object `Input` from `keras`.\n",
    "<br>\n",
    "We have to specify how many input values there are, which we can get using the `shape` parameter value from one sample of the training set.\n",
    "\n",
    "まず、`keras`の`Input`オブジェクトを使って、ネットワークの入力層を定義しましょう。<br>\n",
    "入力値の数を指定する必要がありますが、これはトレーニングセットの1つのサンプルの `shape` パラメータの値から得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (784,)\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train[0].shape\n",
    "print(\"Input shape:\", input_shape)\n",
    "vector_input = Input(shape = input_shape, name='input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create the first hidden layer of the network. It is a layer of neurons that are fully connected (fc) to the input layer.\n",
    "<br>\n",
    "Namely, each of the neurons of the layer `fc1` are connected to all of the input lines provided by the input placeholder.\n",
    "\n",
    "入力プレースホルダは、トレーニングセットの各784サンプルの「入力線」を定義する。\n",
    "<br>\n",
    "次は、ネットワークの最初の隠れ層を作成しましょう。全ての入力に完全に接続されているニューロンの層、いわゆる__全結合層__です。\n",
    "<br>\n",
    "すなわち、層`fc1`の各ニューロンは、入力プレースホルダのすべての入力線に接続される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fc1 = Dense(128, activation='relu', name='fc1')(vector_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer `fc1` is of type `Dense`. In `keras`, a fully connected layer is called a `Dense` layer.\n",
    "<br>\n",
    "The layer `fc1` has 128 neurons. The activation (nonlinear function) is of type `relu`. This is a simple and most commonly used activation function called _Rectified Linear Unit (ReLU)_. The output of ReLU is the same as the input if the input is positive, and 0 if it is negative - see graph below.\n",
    "\n",
    "`fc1`層のタイプは` Dense`です。`keras`では、全結合層は` Dense`層と呼ばれます。\n",
    "<br>\n",
    "`fc1`層は128ニューロンを持っています。使っている非線形関数（_活性化関数_）は`relu`型です。これは、_正規化線形関数（Rectified Linear Unit：ReLU）_と呼ばれるシンプルで最も一般的に使用される活性化関数です。ReLUの出力は、入力が正の場合は入力と同じであり、負の場合は0です。\n",
    "\n",
    "<img src=\"./img/relu.png\" width=\"300\">\n",
    "\n",
    "\n",
    "Note that the layer `fc1` is a function of the layer `vector_input`, which provides the inputs to the layer `fc1`. This is the way the `keras` functional API connects the layers to build a network.\n",
    "<br>\n",
    "The layer `fc1` has a weight for all the connections between the 784 inputs (plus a 1) and the 128 neurons. Thus, there are `785x128 = 100480` weights.\n",
    "\n",
    "`fc1`層は` vector_input`の関数です。すなわち、入力プレースホルダ `vector_input`は` fc1`層の入力を提供します。このようにして、 `keras`APIでは層を接続してネットワークを構築します。\n",
    "<br>\n",
    "層`fc1`には、784の入力線（そして 1）と128のニューロンがあって、その間のすべての接続に重みをあります。したがって、重みが全部で`785x128 = 100480`あります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add another fully connected layer with 128 neurons:\n",
    "\n",
    "128個のニューロンを持つ別の全結合層を追加しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fc2 = Dense(128, activation='relu', name='fc2')(fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new layer `fc2` also of type `Dense` takes the previous layer `fc1` as input.\n",
    "\n",
    "この`fc2`層も`Dense`型です。前の`fc1`を入力として使っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the neural network is composed of two layers of `128` neurons.\n",
    "<br>\n",
    "When an input vector of size `784` is presented to the network:\n",
    "- `fc1` computes `128` weighted sums of these `784` values and apply the `relu` function to each of these sums.\n",
    "- `fc2` computes `128` weighted sums of the `128` outputs of `fc1` and apply the `relu` function to each of these sums.\n",
    "\n",
    "この段階で、ニューラルネットワークは2層があって、それぞれの層に128のニューロンがあります。\n",
    "<br>\n",
    "サイズ784の入力ベクトルをネットワークに入れると、\n",
    " -  `fc1`はこれらの784値から128の加重和を計算し、各和に`relu`関数を適用します。\n",
    " -  `fc2`は`fc1`の128の出力から128の加重和を計算し、それぞれの和に`relu`関数を適用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us add another fully connected layer for the output.\n",
    "\n",
    "最後に、ネットワーク出力になるもう1つの全結合層を追加しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = Dense(10, activation='softmax', name='output')(fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new layer `output` is also a fully connected layer. However it has only `10` neurons and the activation is no longer of type `relu`.\n",
    "<br>\n",
    "The activation function `softmax` is a function with multiple inputs and multiple outputs, in this case, `10` of each.\n",
    "<br>\n",
    "It is defined by the equation below.\n",
    "\n",
    "この`output`層も全結合層ですが、10個のニューロンしか持っていません。\n",
    "<br>\n",
    "また、活性化関数は`relu`型ではなく、ソフトマックス関数（`softmax`）です。\n",
    "<br>\n",
    "以下は`softmax`関数の定義です。\n",
    "\n",
    "$\\text{softmax}\\left(i_0, i_1, \\cdots, i_{n-1}\\right) = \\left(\\frac{\\exp{i_0}}{\\sum_k \\exp{i_k}}, \\frac{\\exp{i_1}}{\\sum_k \\exp{i_k}}, \\cdots, \\frac{\\exp{i_{n-1}}}{\\sum_k \\exp{i_k}}\\right) $\n",
    " \n",
    "The outputs of the softmax function take values between 0 and 1, and their sum is 1.\n",
    "\n",
    "`softmax`の出力は０から１の間の値を取り、それらの合計は１です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of outputs of the `output` layer corresponds to the number of digits to classifiy in the MNIST dataset. For a given input, one of these outputs will have the highest value. The digit to which this output corresponds is considerd to be the result of the classification. (E.g. if the outputs from `output` are [0, 0, 0.7, 0, 0, 0, 0.2, 0, 0.1, 0], the third one is the largest, which corresponds to the digit `2`).\n",
    "<br>\n",
    "Using this way to determine the resulting class, the network is able to perform the digit classification. \n",
    "<br>\n",
    "The network still needs to \"learn\" . The goal of this learning is to find adequate values for the weights of `fc1`, `fc2` and `output` such that when presented with a picture of a given digit, the network predicts the correct value of the digit by activating the corresponding output of `output`.\n",
    "\n",
    "`output`層の出力の数は、MNISTデータセットで分類する桁数に対応します。ネットワークにある入力を与えられたら、`output`層のどちらか1つの出力が最も高い値を持ちます。その出力に対応する数字は分類の結果であると見なされます。（例えば、`output`層からの出力が[0, 0, 0.7, 0, 0, 0, 0.2, 0, 0.1, 0]だとすると、その3番目の値は最大であり、それが数字「2」に対応する）\n",
    "<br>\n",
    "今のやり方で結果クラスを決定して、ネットワークが手書き数字の分類を実行できます。\n",
    "<br>\n",
    "ネットワークはまだ「学習」する必要があります。この学習によって、`fc1`、`fc2`と`output`層の重みの適切な値を見つかります。すると、手書き数字の図が与えられたら、その数字に対応する`output`の出力をアクティブになるようになります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should tell `keras` that we are done with creating our network.\n",
    "\n",
    "これでネットワーク構造の定義が終わったため、ネットワークを作成しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network = Model(vector_input, output, name='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Model` function creates the network (or model) by indicating the input and the output, respectively `vector_input` and `output`.\n",
    "\n",
    "Model関数はネットワーク（モデル）を作成します。入力と出力がそれぞれ`vector_input`と`output`と指示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `keras` models have a convenient function to display their structure.\n",
    "\n",
    "`keras`のモデルの構成を表示するには以下の関数を使えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `summary` function displays all the information about the network layers.\n",
    "<br>\n",
    "The value `None` in the shapes indicates that any size is possible. For example the input can be a single sample of size `(1, 784)` or our whole training set of size `(35000, 784)`.\n",
    "<br>\n",
    "The summary indicates the number of parameters that are trainable. This particular model has `118,282` that are all trainable.\n",
    "\n",
    "`summary`関数は、ネットワークの層に関する情報を表示します。\n",
    "<br>\n",
    "形状の値が`None`の場合、任意のサイズが使えることを示します。 たとえば、入力にはサイズ（1、784）の単一のサンプルも使えて、サイズ（35000、784）の全トレーニングセットも使えます。\n",
    "<br>\n",
    "トレーニング可能なパラメーター（重み）の数も示しています。 このモデルはパラメータを118,282を持って、すべて訓練可能なパラメータです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Note: The network we created has only 3 layers. Nowadays deep neural networks with a much larger number of layers (hundreds or even thousands) are often used. However, a lot of data is needed to train such deep networks.\n",
    "\n",
    "注：作成したネットワークは3つの層しかありません。最近では、はるかに多数の層（数百、さらには数千）を持つディープニューラルネットワークがよく使用されます。しかし、そのようなDNNを学習させるには、大量のデータが必要です。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try  it yourself ! / 自分で試そう！\n",
    "\n",
    "[Click here](session9-playground.ipynb) to open a sample notebook where you can create your own model.\n",
    "\n",
    "[ここをクリックして](session9-playground.ipynb)練習ノートブックを開いて、自分でニューラルネットワークを構築してみてください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
