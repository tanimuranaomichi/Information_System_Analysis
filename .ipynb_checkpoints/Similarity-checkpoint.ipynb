{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aVVn6hB9Zei"
   },
   "source": [
    "# Preprocessing and calculate similarity\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆã®ç›®æ¨™ã¯è‡ªåŠ›ã§æ–‡æ›¸ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨  \n",
    "æœ€çµ‚çš„ã«Wikipediaã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å›½ã®é¡ä¼¼åº¦ã‚’æ¸¬ã‚Š  \n",
    "æ—¥æœ¬ã¨ä¼¼ã¦ã„ã‚‹å›½ã‚’æ¢ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "N5-315WVmN64",
    "outputId": "8087c6f8-50b8-4a73-d384-56df8f3406ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (from nltk) (4.60.0)\n",
      "Requirement already satisfied: regex in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: gensim in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (from gensim) (1.20.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/tanimuranaomichi/miniforge3/envs/python38/lib/python3.8/site-packages (from gensim) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M8iK7xBDTmtf"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "iBUvXHj7mRls",
    "outputId": "4a777a79-e94e-483b-dbfe-46747e214ecb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tanimuranaomichi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tanimuranaomichi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tanimuranaomichi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpg2beFhKA2R"
   },
   "source": [
    "## 1. Calculate similarity\n",
    "\n",
    "ä»¥ä¸‹ã®ä¸‰ã¤ã®æ–‡ã‚’è€ƒãˆã‚‹  \n",
    "Doc A : \"I like apples and a strawberries. I will buy an apple tomorrow. \"  \n",
    "Doc B : \"I bought some apples and strawberries. I will eat an apple tomorrow.\"  \n",
    "Doc C : \"I play basketball every day. I like Michael Jordan.\"  \n",
    "\n",
    "Doc Aã¨Doc Bã¯ä¼¼ã¦ã„ãã†ã ãŒã€Doc Cã¯Doc Aã¨ã‚‚Doc Bã¨ã‚‚ä¼¼ã¦ã„ãªã•ãã†  \n",
    "ã“ã‚Œã‚’é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ç¢ºã‹ã‚ã‚‹\n",
    "\n",
    "é¡ä¼¼åº¦ã®è¨ˆç®—ã®ä»•æ–¹ã¯ã„ãã¤ã‹ã‚ã‚‹\n",
    "\n",
    "- é›†åˆãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦\n",
    "  - Jaccardä¿‚æ•°\n",
    "  - Diceä¿‚æ•°\n",
    "  - Simpsonä¿‚æ•°\n",
    "- ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦\n",
    "  - ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢\n",
    "  - ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1rpPCaUeOWE"
   },
   "source": [
    "### é›†åˆãƒ™ãƒ¼ã‚¹\n",
    "\n",
    "æ–‡æ›¸ã‚’å˜èªã®é›†åˆã«å¤‰æ›ã™ã‚‹  \n",
    "é›†åˆãªã®ã§é‡è¤‡ã—ãŸå˜èªã¯å‰Šé™¤ã™ã‚‹  \n",
    "å‰å‡¦ç†ã¯ä»Šå›ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹   \n",
    "\n",
    "Doc A : \"I like apples and a strawberries. I will buy an apple tomorrow. \"  \n",
    "Doc B : \"I bought some apples and strawberries. I will eat an apple tomorrow.\"  \n",
    "Doc C : \"I play basketball every day. I like Michael Jordan.\"  \n",
    "â†“    \n",
    "Set A : {'a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'}  \n",
    "Set B : {'an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'}  \n",
    "Set C : {'basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'}  \n",
    "\n",
    "ã“ã®é›†åˆãŒæ–‡æ›¸ã®ç‰¹å¾´ã‚’è¡¨ã—ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uts5Ns2eKDaW"
   },
   "source": [
    "#### Jaccardä¿‚æ•°\n",
    "Jaccardä¿‚æ•°ã¯äºŒã¤ã®é›†åˆA,Bã«å¯¾ã—ã¦å®šç¾©ã•ã‚Œã‚‹é¡ä¼¼åº¦ã§ã‚ã‚‹  \n",
    "è¨ˆç®—å¼ã¯ä»¥ä¸‹ã®é€šã‚Š\n",
    "\n",
    "\\begin{equation}\n",
    "J(A,B)=\\dfrac{|A\\cap B|}{|A \\cup B|}\n",
    "\\end{equation}\n",
    "\n",
    "å…±é€šéƒ¨åˆ†ã®å‰²åˆãŒå¤§ãã‘ã‚Œã°ãã®äºŒã¤ã®æ–‡æ›¸ã¯ä¼¼ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wqr10Mw-K5UQ"
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(set_a,set_b):\n",
    "  # ç©é›†åˆã®è¦ç´ æ•°ã‚’è¨ˆç®—\n",
    "  num_intersection = len(set.intersection(set_a, set_b))\n",
    "  # å’Œé›†åˆã®è¦ç´ æ•°ã‚’è¨ˆç®—\n",
    "  num_union = len(set.union(set_a, set_b))\n",
    "  #Jaccardä¿‚æ•°ã‚’ç®—å‡ºã€€ç©ºé›†åˆã®æ™‚ã¯1ã‚’å‡ºåŠ›\n",
    "  try:\n",
    "      return float(num_intersection) / num_union\n",
    "  except ZeroDivisionError:\n",
    "      return 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "MZSFY5urK8eT",
    "outputId": "e74717ef-99ae-4b97-85dc-ac99ed2fd3bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard(a, b) =  0.5714285714285714\n",
      "jaccard(a, c) =  0.11764705882352941\n",
      "jaccard(b, c) =  0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
    "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
    "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
    "\n",
    "print(\"jaccard(a, b) = \", jaccard_similarity(set_a, set_b)) #Jaccardä¿‚æ•°ã‚’è¨ˆç®—\n",
    "print(\"jaccard(a, c) = \", jaccard_similarity(set_a, set_c))\n",
    "print(\"jaccard(b, c) = \", jaccard_similarity(set_b, set_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXBk5SiTMmGf"
   },
   "source": [
    "\n",
    "nltkã§å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹  \n",
    "å®šç¾©ã¨åŒã˜ã‚ˆã†ã«è¨ˆç®—ã‚’è¡Œã†ã®ã§ã€å…¥åŠ›ã¯é›†åˆ  \n",
    "è·é›¢ã«ãªã£ã¦ã„ã‚‹ã¨ã“ã‚ã«ã¯æ³¨æ„ãŒå¿…è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "lZQ9q8mFLJTO",
    "outputId": "ce84c908-60fa-4740-8d28-69305bd050a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard(a, b) =  0.5714285714285714\n",
      "jaccard(a, c) =  0.11764705882352944\n",
      "jaccard(b, c) =  0.05555555555555558\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import jaccard_distance\n",
    "\n",
    "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
    "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
    "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
    "\n",
    "# Jaccardè·é›¢ã«ãªã£ã¦ã„ã‚‹ã®ã§ã€é¡ä¼¼åº¦ã«å¤‰æ›ã™ã‚‹ã¨ãã¯1ã‹ã‚‰å¼•ã\n",
    "print(\"jaccard(a, b) = \", 1 - jaccard_distance(set_a, set_b))\n",
    "print(\"jaccard(a, c) = \", 1 - jaccard_distance(set_a, set_c))\n",
    "print(\"jaccard(b, c) = \", 1 - jaccard_distance(set_b, set_c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lyCVTfePwB2"
   },
   "source": [
    "#### SÃ¸rensen-Diceä¿‚æ•°\n",
    "\n",
    "Jaccardä¿‚æ•°ã§ã¯åˆ†æ¯ã¯ã®å’Œé›†åˆã§ã‚ã£ãŸãŸã‚  \n",
    "ç‰‡æ–¹ã®é›†åˆãŒã¨ã¦ã‚‚å¤§ãã„ã¨å…±é€šéƒ¨åˆ†ãŒå¤§ããã¦ã‚‚ä¿‚æ•°ã®å€¤ãŒå°ã•ããªã£ã¦ã—ã¾ã†ã¨ã„ã†å•é¡ŒãŒã‚ã‚‹  \n",
    "SÃ¸rensen-Diceä¿‚æ•°ã§ã¯ã€åˆ†æ¯ã‚’äºŒã¤ã®é›†åˆã®å¤§ãã•ã®å¹³å‡ã‚’ã¨ã‚‹ã“ã¨ã§ã€ãã®å½±éŸ¿ã‚’ç·©å’Œã—ã¦ã„ã‚‹  \n",
    "\n",
    "$\n",
    "DSC(A,B) = \\dfrac{|A\\cap B|}{\\dfrac{|A| + |B|}{2}} = \\dfrac{2|A\\cap B|}{|A| + |B|}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0M0RikFPR3Qr"
   },
   "outputs": [],
   "source": [
    "def dice_similarity(set_a, set_b):\n",
    "  num_intersection =  len(set.intersection(set_a, set_b))\n",
    "  sum_nums = len(set_a) + len(set_b)\n",
    "  try:\n",
    "    return 2 * num_intersection / sum_nums\n",
    "  except ZeroDivisionError:\n",
    "    return 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "ZZQFbXlESPWl",
    "outputId": "e5248c67-0b7e-4e0a-e541-517f22d6b1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice(a, b) =  0.7272727272727273\n",
      "dice(a, c) =  0.21052631578947367\n",
      "dice(b, c) =  0.10526315789473684\n"
     ]
    }
   ],
   "source": [
    "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
    "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
    "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
    "\n",
    "print(\"dice(a, b) = \", dice_similarity(set_a, set_b))\n",
    "print(\"dice(a, c) = \", dice_similarity(set_a, set_c))\n",
    "print(\"dice(b, c) = \", dice_similarity(set_b, set_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxtliI-HPwRE"
   },
   "source": [
    "#### Szymkiewicz-Simpsonä¿‚æ•°\n",
    "\n",
    "å·®é›†åˆã®è¦ç´ æ•°ã®å½±éŸ¿ã‚’æ¥µé™ã¾ã§æŠ‘ãˆãŸã®ãŒSzymkiewicz-Simpsonä¿‚æ•°    \n",
    "$\n",
    "overlap(ğ´,ğµ) = \\dfrac{|A\\cap B|}{\\min(|A|, |B|)}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zgGJ5GhmUduH"
   },
   "outputs": [],
   "source": [
    "def simpson_similarity(list_a, list_b):\n",
    "  num_intersection = len(set.intersection(set(list_a), set(list_b)))\n",
    "  min_num = min(len(set(list_a)), len(set(list_b)))\n",
    "  try:\n",
    "    return num_intersection / min_num\n",
    "  except ZeroDivisionError:\n",
    "    if num_intersection == 0:\n",
    "      return 1.0\n",
    "    else:\n",
    "      return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "g_1Gjy4IV9eo",
    "outputId": "bd752621-a182-4b35-d7f9-842de47d1a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpson(a, b) =  0.7272727272727273\n",
      "simpson(a, c) =  0.25\n",
      "simpson(b, c) =  0.125\n"
     ]
    }
   ],
   "source": [
    "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
    "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
    "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
    "\n",
    "print(\"simpson(a, b) = \", simpson_similarity(set_a, set_b)) \n",
    "print(\"simpson(a, c) = \", simpson_similarity(set_a, set_c)) \n",
    "print(\"simpson(b, c) = \", simpson_similarity(set_b, set_c)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-T32gmnZIyt"
   },
   "source": [
    "#### Exercise 1\n",
    "è‰²ã€…ãªé›†åˆã‚’ä½œã£ã¦é›†åˆãƒ™ãƒ¼ã‚¹æ‰‹æ³•ã®æ¯”è¼ƒã‚’ã—ã‚ˆã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "oJwJpZpdYtz9",
    "outputId": "a644cc06-c7b7-4f2b-82dc-ecd067767cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard similarity:\n",
      "0.1111111111111111\n",
      "0.05263157894736842\n",
      "0.0625\n",
      "dice similarity:\n",
      "0.2\n",
      "0.1\n",
      "0.11764705882352941\n",
      "simpson similarity:\n",
      "0.2222222222222222\n",
      "0.1111111111111111\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "set_a = set(['a', 'an', 'and', 'apple', 'apples', 'buy', 'i', 'like', 'strawberries', 'tomorrow', 'will'])\n",
    "set_b = set(['an', 'and', 'apple', 'apples', 'bought', 'eat', 'i', 'some', 'strawberries', 'tomorrow', 'will'])\n",
    "set_c = set(['basketball', 'day', 'every', 'i', 'jordan', 'like', 'michael', 'play'])\n",
    "set_d = set(['i', 'am', 'a', 'student', 'learning', 'informatics', 'at', 'kyoto', 'university']) # å¤§ãã‚ã®é›†åˆã‚’ä½œã£ã¦è©¦ã—ã¦ã¿ã‚ˆã†\n",
    "\n",
    "print(\"jaccard similarity:\")\n",
    "print(jaccard_similarity(set_d, set_a))\n",
    "print(jaccard_similarity(set_d, set_b))\n",
    "print(jaccard_similarity(set_d, set_c))\n",
    "\n",
    "print(\"dice similarity:\")\n",
    "print(dice_similarity(set_d, set_a))\n",
    "print(dice_similarity(set_d, set_b))\n",
    "print(dice_similarity(set_d, set_c))\n",
    "\n",
    "print(\"simpson similarity:\")\n",
    "print(simpson_similarity(set_d, set_a))\n",
    "print(simpson_similarity(set_d, set_b))\n",
    "print(simpson_similarity(set_d, set_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-Hm34tgXCbh"
   },
   "source": [
    "### ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ \n",
    "\n",
    "\n",
    "æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¡¨ç¾ã—é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹  \n",
    "ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®æ‰‹æ³•ã¯è‰²ã€…ã‚ã‚‹ãŒä»Šå›ã¯BoW(Bag of Words)ã§èª¬æ˜ã™ã‚‹  \n",
    "\n",
    "BoWã¯æ–‡ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾ã™ã‚‹æ–¹æ³•ã®ä¸€ã¤  \n",
    "æƒ³å®šã—ã¦ã„ã‚‹å˜èªã®ç·æ•°ã‚’Nã¨ã™ã‚‹ã¨ã€å„æ¬¡å…ƒãŒå„å˜èªã«å¯¾å¿œã™ã‚‹Næ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’è€ƒãˆã‚‹  \n",
    "å„æ¬¡å…ƒã®å€¤ã¯ãã®å˜èªãŒæ–‡æ›¸ä¸­ã§å‡ºãŸå›æ•°\n",
    "\n",
    "ä¾‹ï¼‰  \n",
    "Doc A : \"I like apples and a strawberries. I will buy an apple tomorrow. \"  \n",
    "Doc B : \"I bought some apples and strawberries. I will eat an apple tomorrow.\"  \n",
    "Doc C : \"I play basketball every day. I like Michael Jordan.\"  \n",
    "â†“  \n",
    "å…¨å˜èªã¯19å€‹ã§ã€å„æ¬¡å…ƒã®å€¤ã¯ä»¥ä¸‹ã®å˜èªã®å€‹æ•°ã«å¯¾å¿œã™ã‚‹BoWã‚’è€ƒãˆã‚‹  \n",
    "['an', 'and', 'apple', 'apples', 'basketball', 'bought', 'buy', 'day', 'eat', 'every', 'i', 'jordan', 'like', 'michael', 'play', 'some', 'strawberries', 'tomorrow', 'will']  \n",
    "â†“  \n",
    "BoW A : [1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1]  \n",
    "BoW B : [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1]  \n",
    "BoW C : [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0]  \n",
    "\n",
    "ã“ã®ãƒ™ã‚¯ãƒˆãƒ«ãŒæ–‡æ›¸ã®ç‰¹å¾´ã‚’è¡¨ã—ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQOjHTfCeXjs"
   },
   "source": [
    "\n",
    "#### ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢\n",
    "\n",
    "å„æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ã™ã“ã¨ãŒå‡ºæ¥ãŸã®ã§  \n",
    "ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ãŒè¨ˆç®—ã§ãã‚‹  \n",
    "ã“ã®è·é›¢ãŒå°ã•ã‘ã‚Œã°ä¼¼ã¦ã„ã‚‹ã¨è€ƒãˆã‚‹ã“ã¨ãŒå‡ºæ¥ã‚‹\n",
    "\n",
    "\\begin{equation}\n",
    "d(v_1,v_2) =(\\sum_{i=1}^n (v_{1i}-v_{2i})^2)^{\\frac{1}{2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YtEzuSDKZbpV"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(list_a, list_b):\n",
    "  diff_vec = np.array(list_a) - np.array(list_b)\n",
    "  return np.linalg.norm(diff_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "4Sr_ZYj7azLV",
    "outputId": "c10469e8-538e-4806-afce-01e994b769b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean_distance(bow_a, bow_b) =  2.23606797749979\n",
      "euclidean_distance(bow_a, bow_c) =  3.7416573867739413\n",
      "euclidean_distance(bow_b, bow_c) =  4.123105625617661\n"
     ]
    }
   ],
   "source": [
    "bow_a = [1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1]  \n",
    "bow_b = [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1]  \n",
    "bow_c = [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0]  \n",
    "\n",
    "print(\"euclidean_distance(bow_a, bow_b) = \",euclidean_distance(bow_a, bow_b))\n",
    "print(\"euclidean_distance(bow_a, bow_c) = \",euclidean_distance(bow_a, bow_c))\n",
    "print(\"euclidean_distance(bow_b, bow_c) = \",euclidean_distance(bow_b, bow_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfKcQd5SiBb-"
   },
   "source": [
    "#### ãƒŸãƒ³ã‚³ãƒ•ã‚¹ã‚­ãƒ¼è·é›¢\n",
    "\n",
    "ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’ä¸€èˆ¬åŒ–ã—ãŸè·é›¢\n",
    "pã®å€¤ã‚’å¤‰ãˆã‚‹ã“ã¨ã§è‰²ã€…ãªè·é›¢ã‚’è¡¨ç¾ã§ãã‚‹  \n",
    "\n",
    "\\begin{equation}\n",
    "d(v_1,v_2) = (\\sum_{i=1}^n |v_{1i}-v_{2i}|^p)^{\\frac{1}{p}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx46KLSNhjI2"
   },
   "source": [
    "#### Exercise 2\n",
    "ãƒŸãƒ³ã‚³ãƒ•ã‚¹ã‚­ãƒ¼è·é›¢ã‚’è¨ˆç®—ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ã„ã¦  \n",
    "p=1,2,3ã§è·é›¢ã‚’è¨ˆç®—ã—ã¦ã¿ã‚ˆã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "X6UMFh58bexH"
   },
   "outputs": [],
   "source": [
    "# np.linalg.normã«ã¤ã„ã¦èª¿ã¹ã‚ˆã†\n",
    "def minkowski_distance(list_a, list_b, p):\n",
    "  diff_vec = np.array(list_a) - np.array(list_b)\n",
    "  return np.linalg.norm(diff_vec, ord=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "jKMIMbyJc8eH",
    "outputId": "260027a1-408d-4b7a-9490-0e7c2314a0f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "14.0\n",
      "17.0\n",
      "2.23606797749979\n",
      "3.7416573867739413\n",
      "4.123105625617661\n",
      "1.7099759466766968\n",
      "2.4101422641752297\n",
      "2.571281590658235\n"
     ]
    }
   ],
   "source": [
    "# p=1\n",
    "print(minkowski_distance(bow_a, bow_b, 1))\n",
    "print(minkowski_distance(bow_a, bow_c, 1))\n",
    "print(minkowski_distance(bow_b, bow_c, 1))\n",
    "\n",
    "# p=2\n",
    "print(minkowski_distance(bow_a, bow_b, 2))\n",
    "print(minkowski_distance(bow_a, bow_c, 2))\n",
    "print(minkowski_distance(bow_b, bow_c, 2))\n",
    "\n",
    "# p=3\n",
    "print(minkowski_distance(bow_a, bow_b, 3))\n",
    "print(minkowski_distance(bow_a, bow_c, 3))\n",
    "print(minkowski_distance(bow_b, bow_c, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIyabGRTKGwA"
   },
   "source": [
    "#### ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦\n",
    "\n",
    "ãƒ™ã‚¯ãƒˆãƒ«ã®ãªã™è§’ã«ç€ç›®ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹  \n",
    "\n",
    "\\begin{equation}\n",
    "similarity(A, B)=cos(\\theta)=\\dfrac{\\sum_{i=1}^n A_iB_i}{{\\sqrt A}{\\sqrt B}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fWy619amlwp"
   },
   "source": [
    "#### Exercise 3\n",
    "ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ã„ã¦è¨ˆç®—ã—ã‚ˆã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xDhwqTN5yJGQ"
   },
   "outputs": [],
   "source": [
    "# numpy.array ã«ã¤ã„ã¦èª¿ã¹ã‚ˆã†\n",
    "def cosine_similarity(list_a, list_b):\n",
    "  # ã‚ã¨ã§æ¶ˆã™\n",
    "  inner_prod = np.array(list_a).dot(np.array(list_b))\n",
    "  norm_a = np.linalg.norm(list_a)\n",
    "  norm_b = np.linalg.norm(list_b)\n",
    "  try:\n",
    "      return inner_prod / (norm_a*norm_b)\n",
    "  except ZeroDivisionError:\n",
    "      return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "Sew3u-YezRrX",
    "outputId": "52aacae6-4480-4975-c8fe-415dccfa38af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(bow_a, bow_b) =  0.8153742483272114\n",
      "cosine_similarity(bow_a, bow_c) =  0.41812100500354543\n",
      "cosine_similarity(bow_b, bow_c) =  0.3223291856101521\n"
     ]
    }
   ],
   "source": [
    "bow_a = [1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1]\n",
    "bow_b = [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "bow_c = [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0]\n",
    "\n",
    "print(\"cosine_similarity(bow_a, bow_b) = \",cosine_similarity(bow_a, bow_b))\n",
    "print(\"cosine_similarity(bow_a, bow_c) = \",cosine_similarity(bow_a, bow_c))\n",
    "print(\"cosine_similarity(bow_b, bow_c) = \",cosine_similarity(bow_b, bow_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao0jywXqKIFS"
   },
   "source": [
    "### é›†åˆãƒ™ãƒ¼ã‚¹ã¨ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¯”è¼ƒ\n",
    "\n",
    "é›†åˆæ¼”ç®—ã®æ–¹ã¯ä¸€ã¤ä¸€ã¤ã®æ–‡æ›¸ãŒå°ã•ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ€§èƒ½ãŒé«˜ã„  \n",
    "æ–‡æ›¸ãŒã‚ã‚‹ç¨‹åº¦å¤§ãããªã‚‹ã¨ãƒ™ã‚¯ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®æ–¹ãŒæœ‰ç”¨ã«ãªã‚‹  \n",
    "ãã®ä»£ã‚ã‚Šã€èªå½™é›†åˆãŒå¤§ãããªã‚Šè¨ˆç®—é‡ãŒå¤§ãããªã£ã¦ã—ã¾ã†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1IXMwIyhU-6"
   },
   "source": [
    "### Exercise 4\n",
    "çŸ­ã„æ–‡ç« ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨é•·ã„æ–‡ç« ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªåˆ†ã§ä½œã‚Š    \n",
    "Jaccardä¿‚æ•°ã¨ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¦æ¯”è¼ƒã—ã¦ã¿ã‚ˆã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BpkcXVDBhZg8"
   },
   "outputs": [],
   "source": [
    "short_docs = []\n",
    "long_docs = []\n",
    "\n",
    "# ãªã«ã‚’ã‚„ã‚‰ã›ãŸã„ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuXSHk01KLza"
   },
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "é›†åˆé–“ã®å…±é€šéƒ¨åˆ†ã‚„ãƒ™ã‚¯ãƒˆãƒ«é–“ã®è·é›¢ã‚„è§’åº¦ã§é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ã“ã¨ãŒå‡ºæ¥ãŸ  \n",
    "é›†åˆã‚„ãƒ™ã‚¯ãƒˆãƒ«ãŒæ–‡æ›¸ã®ç‰¹å¾´ã‚’ä¸Šæ‰‹ãè¡¨ã›ã¦ã„ãªã„ã¨é¡ä¼¼åº¦ãŒä¸Šæ‰‹ãæ¸¬ã‚Œãªã„  \n",
    "æ–‡æ›¸ã‹ã‚‰ã©ã®ã‚ˆã†ã«é›†åˆã‚„ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œã‚‹ã‹ãŒã¨ã¦ã‚‚å¤§äº‹  \n",
    " \n",
    "é©åˆ‡ãªå‰å‡¦ç†ã‚’è¡Œã†ã“ã¨ã§ç‰¹å¾´ã‚’æ‰ãˆãŸé¡ä¼¼åº¦ã‚’æ¸¬ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹    \n",
    "å¾ŒåŠã¯ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«çµã£ã¦ç·´ç¿’ã—ã¦ã„ã  \n",
    "\n",
    "1. Clearning\n",
    "2. Tokenize\n",
    "3. Stemming\n",
    "4. Remove stop words\n",
    "5. Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4ispTSLKM-z"
   },
   "source": [
    "### 2-1. Clearning\n",
    "\n",
    "ä¸Šã®ä¾‹ã§ã¯ç¶ºéº—ãªæ–‡ç« ã°ã‹ã‚Šæ‰±ã£ã¦ã„ãŸãŒã€å®Ÿéš›ã¯ã‚‚ã£ã¨æ±šã„   \n",
    "Webã‹ã‚‰å–ã£ã¦ããŸãƒ‡ãƒ¼ã‚¿ã ã¨htmlã‚¿ã‚°ãŒæ®‹ã£ã¦ã„ãŸã‚Šã€å¤‰ãªè¨˜å·ãŒå…¥ã£ã¦ã„ãŸã‚Šã™ã‚‹  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZM-e5AZT316r"
   },
   "outputs": [],
   "source": [
    "documents=[\"I like apples and a strawberries. I will buy an apple tomorrow @Fresco.\",\n",
    "           \"I bought some apples and strawberries. I will eat an apple <b>tomorrow.</b>\",\n",
    "           \"I play basketball every day. I like Michael Jordan (born February 17, 1963).\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh56eU_levzv"
   },
   "source": [
    "ä»Šã¯ä¸‰ã¤ãªã®ã§æ‰‹å‹•ã§æ¶ˆã›ã‚‹ãŒ  \n",
    "å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ã¨ãã«ã¯è‡ªå‹•ã§ç¶ºéº—ã«ã§ããªã„ã¨ã„ã‘ãªã„  \n",
    "ç¶ºéº—ã«ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06coot4PnVgS"
   },
   "source": [
    "#### Exercise 5\n",
    "\n",
    "æ­£è¦è¡¨ç¾ã‚’ä½¿ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¶ºéº—ã«ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ã“ã†\n",
    "\n",
    "å‚è€ƒ: æ­£è¦è¡¨ç¾ (https://uxmilk.jp/41416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "rt3NL8Ux5Q4E",
    "outputId": "84647b30-72a8-4a00-ad3a-cc8526d643ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test I like apples and a strawberries. I will buy an apple tomorrow Fresco.\n",
      "test I bought some apples and strawberries. I will eat an apple tomorrow.\n",
      "test I play basketball every day. I like Michael Jordan.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cleaning_text(text):\n",
    "    # @ã®å‰Šé™¤\n",
    "    pattern1 = '@'\n",
    "    text = re.sub(pattern1, '', text)    \n",
    "    # <b>ã‚¿ã‚°ã®å‰Šé™¤\n",
    "    pattern2 = '</*b>'\n",
    "    text = re.sub(pattern2, '', text)    \n",
    "    # ()å†…ã‚’å‰Šé™¤\n",
    "    pattern3 = '\\s*\\(.*\\)'\n",
    "    text = re.sub(pattern3, '', text)\n",
    "    return text\n",
    "  \n",
    "\n",
    "for text in documents:\n",
    "    print(cleaning_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcgcKWkRflR5"
   },
   "source": [
    "#### Option 1\n",
    "\n",
    "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¶ºéº—ã«ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ã¿ã‚ˆã†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "GcsdHgV-h26y"
   },
   "outputs": [],
   "source": [
    "text = '<p><b>Natural language processing</b> (<b>NLP</b>) is a subfield of <a href=\"/wiki/Computer_science\" title=\"Computer science\">computer science</a>, <a href=\"/wiki/Information_engineering_(field)\" title=\"Information engineering (field)\">information engineering</a>, and <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a> concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of <a href=\"/wiki/Natural_language\" title=\"Natural language\">natural language</a> data.</p>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing is a subfield of a\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cleaning_text2(text):\n",
    "    # @ã®å‰Šé™¤\n",
    "    pattern1 = '@'\n",
    "    text = re.sub(pattern1, '', text)    \n",
    "    # <b>ã‚¿ã‚°ã®å‰Šé™¤\n",
    "    pattern2 = '</?(p|b|a|a href.*)>'#??????????????????????????\n",
    "    text = re.sub(pattern2, '', text)    \n",
    "    # ()å†…ã‚’å‰Šé™¤\n",
    "    pattern3 = '\\s*\\(.*\\)'\n",
    "    text = re.sub(pattern3, '', text)\n",
    "    return text\n",
    "  \n",
    "print(cleaning_text2(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1doxCMAGr0_O"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edJ80nTbQgLi"
   },
   "source": [
    "\n",
    "### 2-2. Tokenize\n",
    "\n",
    "ã¾ã æ–‡å­—åˆ—ã®ã¾ã¾ãªã®ã§ã€å˜èªã”ã¨ã«åŒºåˆ‡ã‚‹  \n",
    "è‹±èªã ã¨ç©ºç™½åŒºåˆ‡ã‚Šã§ã‚ˆã„ãŒæ—¥æœ¬èªã ã¨å°‘ã—é¢å€’  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "JGbqTvkyYl2S",
    "outputId": "9c579d6e-133a-42da-8c4e-3322bc5be131"
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "  text = re.sub('[.,]', '', text)\n",
    "  return text.split()\n",
    "\n",
    "for text in documents:\n",
    "  text = cleaning_text(text)\n",
    "  print(tokenize_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K97zCvZBQik9"
   },
   "source": [
    "### 2-3. Stemming, Lemmatize\n",
    "\n",
    "åŒã˜æ„å‘³ã®å˜èªã§ã‚‚ç•°ãªã‚‹å½¢ã‚’ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‚‹  \n",
    "ãã‚Œã‚‰ã‚’åˆ¥ã®å˜èªã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ã®ã¯ä¸è‡ªç„¶  \n",
    "å°æ–‡å­—ã«å¤‰æ›ã—ãŸå¾Œ  \n",
    "Stemmingã‚„Lemmatizeã¨ã„ã†å‡¦ç†ã§åŒã˜å½¢ã«ã™ã‚‹  \n",
    "ä»Šå›ã¯Lemmatizeã®ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7R55rKxZtAz"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn #lemmatizeé–¢æ•°ã®ãŸã‚ã®import\n",
    "\n",
    "def lemmatize_word(word):\n",
    "    # make words lower  example: Python =>python\n",
    "    word=word.lower()\n",
    "    \n",
    "    # lemmatize  example: cooked=>cook\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "      return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "_0sEVvmwaCqA",
    "outputId": "6fb86a52-14cf-47c8-b671-61bd174dcadb"
   },
   "outputs": [],
   "source": [
    "for text in documents:\n",
    "  text = cleaning_text(text)\n",
    "  tokens = tokenize_text(text)\n",
    "  print([lemmatize_word(word) for word in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOPIFqvjfxEg"
   },
   "source": [
    "strawberriesâ†’strawberryã®ã‚ˆã†ã«èªã‚’æ¨™æº–å½¢ã«å¤‰æ›å‡ºæ¥ãŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpUxnB9kQlKv"
   },
   "source": [
    "### 2-4. Remove stop words\n",
    "\n",
    "a, theãªã©ã®æ–‡ç« ã«å¯„ã‚‰ãšä¸€èˆ¬çš„ã«ä½¿ã‚ã‚Œã‚‹å† è©ã€ä»£åè©ã€å‰ç½®è©ãªã©ã‚’ä½¿ã£ã¦ã‚‚æ„å‘³ãŒãªã„  \n",
    "ãã‚Œã‚‰ã®å˜èªã¯stop wordã¨å‘¼ã°ã‚Œã‚‹  \n",
    "nltkã«ã¯å°‚é–€å®¶ãŒå®šç¾©ã—ãŸstop wordã®ãƒªã‚¹ãƒˆãŒã‚ã‚‹ã®ã§ãã‚Œã‚’ä½¿ã†  \n",
    "å¿…è¦ã«å¿œã˜ã¦stop wordã¯è‡ªåˆ†ã§ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ã¹ã  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "dbSLDay-a36N",
    "outputId": "a53a1db9-6fa1-48da-d774-bc900fa0ef31"
   },
   "outputs": [],
   "source": [
    "#1 nltkã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ\n",
    "en_stop = nltk.corpus.stopwords.words('english')\n",
    "print(en_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nX8eIyxfbo6q"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(word, stopwordset):\n",
    "  if word in stopwordset:\n",
    "    return None\n",
    "  else:\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "WckIX0ThbQMy",
    "outputId": "40e02a66-8f45-4963-b41f-a4dd504052e9"
   },
   "outputs": [],
   "source": [
    "for text in documents:\n",
    "  text = cleaning_text(text)\n",
    "  tokens = tokenize_text(text)\n",
    "  tokens = [lemmatize_word(word) for word in tokens]\n",
    "  print([remove_stopwords(word, en_stop) for word in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4kNHhr5f8Vt"
   },
   "source": [
    "ä»Šå›ã¯ã“ã‚Œã ã‘ã§çµ‚ã‚ã‚Šã«ã™ã‚‹ãŒå˜èªã®å‰Šé™¤ã¯ã‹ãªã‚Šé‡è¦  \n",
    "å‡ºç¾é »åº¦ãŒæ¥µç«¯ã«ä½ã„å˜èªã‚’å‰Šé™¤ã—ãŸã‚Šã€å‹•è©ã¨åè©ã«é™å®šã™ã‚‹ãªã©è‰²ã€…ã‚ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "BgjfOITFxwx_",
    "outputId": "6a49e871-c379-4057-b622-0fc432641bd2"
   },
   "outputs": [],
   "source": [
    "def preprocessing_text(text):\n",
    "  text = cleaning_text(text)\n",
    "  tokens = tokenize_text(text)\n",
    "  tokens = [lemmatize_word(word) for word in tokens]\n",
    "  tokens = [remove_stopwords(word, en_stop) for word in tokens]\n",
    "  tokens = [word for word in tokens if word is not None]\n",
    "  return tokens\n",
    "\n",
    "\n",
    "preprocessed_docs = [preprocessing_text(text) for text in documents]\n",
    "preprocessed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCd6YpYbKJSJ"
   },
   "source": [
    "### 2-5. Vectorize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmrBtgPxcwX0"
   },
   "source": [
    "#### BoW(Bag of Words)\n",
    "\n",
    "\n",
    "ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã®å‡ºç¾å›æ•°ã®ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ã—ãŸã‚‚ã®  \n",
    "äººæ‰‹ã§å˜èªã‚’æ•°ãˆãŸã‚Šã™ã‚‹ã®ã¯ä¸å¯èƒ½ãªã®ã§ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å‡¦ç†ã‚’å®Œçµã—ã¦ã—ã¾ãŠã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S69MsPjHcvut"
   },
   "outputs": [],
   "source": [
    "def bow_vectorizer(docs):\n",
    "  word2id = {}\n",
    "  for doc in docs:\n",
    "    for w in doc:\n",
    "      if w not in word2id:\n",
    "        word2id[w] = len(word2id)\n",
    "        \n",
    "  result_list = []\n",
    "  for doc in docs:\n",
    "    doc_vec = [0] * len(word2id)\n",
    "    for w in doc:\n",
    "      doc_vec[word2id[w]] += 1\n",
    "    result_list.append(doc_vec)\n",
    "  return result_list, word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zq3TpP7KO-XP",
    "outputId": "fc36ccec-ad25-447f-bf3c-fa621390c61a"
   },
   "outputs": [],
   "source": [
    "bow_vec, word2id = bow_vectorizer(preprocessed_docs)\n",
    "print(bow_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "udTTbKv8oFpG",
    "outputId": "96df7e79-7318-42e0-e649-a085a7748b80"
   },
   "outputs": [],
   "source": [
    "word2id.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e8h1SMTcyD5"
   },
   "source": [
    "### TF-IDF(Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "BoWã§ã¯å„å˜èªã®é‡ã¿ãŒåŒã˜ã ã£ãŸãŒã€å˜èªã«ã‚ˆã£ã¦é‡è¦åº¦ã¯å¤‰ã‚ã‚‹  \n",
    "å˜èªã®é‡è¦åº¦ã‚’è€ƒæ…®ã—ãŸã®ãŒTF-IDF  \n",
    "\n",
    "TF(t, d) = ã‚ã‚‹å˜èª(t)ã®ã‚ã‚‹æ–‡æ›¸(d)ã«ãŠã‘ã‚‹å‡ºç¾é »åº¦  \n",
    "IDF(t) = ã‚ã‚‹å˜èª(t)ãŒå…¨æ–‡æ›¸é›†åˆ(D)ä¸­ã«ã©ã‚Œã ã‘ã®æ–‡æ›¸ã§å‡ºç¾ã—ãŸã‹ã®é€†æ•°  \n",
    "\n",
    "TF-IDF(t,d) = TF(t, d) * IDF(t)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiKn2p7Bc0bN"
   },
   "outputs": [],
   "source": [
    "def tfidf_vectorizer(docs):\n",
    "  def tf(word2id, doc):\n",
    "    term_counts = np.zeros(len(word2id))\n",
    "    for term in word2id.keys():\n",
    "      term_counts[word2id[term]] = doc.count(term)\n",
    "    tf_values = list(map(lambda x: x/sum(term_counts), term_counts))\n",
    "    return tf_values\n",
    "  \n",
    "  def idf(word2id, docs):\n",
    "    idf = np.zeros(len(word2id))\n",
    "    for term in word2id.keys():\n",
    "      idf[word2id[term]] = np.log(len(docs) / sum([bool(term in doc) for doc in docs]))\n",
    "    return idf\n",
    "  \n",
    "  word2id = {}\n",
    "  for doc in docs:\n",
    "    for w in doc:\n",
    "      if w not in word2id:\n",
    "        word2id[w] = len(word2id)\n",
    "  \n",
    "  return [[_tf*_idf for _tf, _idf in zip(tf(word2id, doc), idf(word2id, docs))] for doc in docs], word2id\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "kz5YnQZclGfL",
    "outputId": "1f8c31c9-4a36-4566-8e20-b76e60b0bcb6"
   },
   "outputs": [],
   "source": [
    "tfidf_vector, word2id = tfidf_vectorizer(preprocessed_docs)\n",
    "print(tfidf_vector)\n",
    "print(word2id.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxCJEOjXYSIP"
   },
   "source": [
    "### Exercise 6\n",
    "BoWã¨TF-IDFã§ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ãã‚Œãã‚Œè¨ˆç®—ã—ã¦ã¿ã‚ˆã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "QD4nID08s-21",
    "outputId": "463337f2-d590-483e-d1dd-ff9ae15fd73b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAUfDUOmJMsp"
   },
   "source": [
    "### Option 2\n",
    "scikit-learn, nltk gensimãã‚Œãã‚Œã«TF-IDFã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ãŒã‚ã‚‹  \n",
    "ãã‚Œãã‚Œã§TF-IDFã‚’è¨ˆç®—ã—ã¦ã¿ã‚ˆã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2tZLjHNxRDG"
   },
   "outputs": [],
   "source": [
    "# scikit-learnã®tfidfã€€ã‚ã¨ã§æ¶ˆã™\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "7x7nd2-ekIs-",
    "outputId": "34a34a2d-2042-4819-81eb-6b31f26858de"
   },
   "outputs": [],
   "source": [
    "#nltk ã®tf-idfã€€ã‚ã¨ã§æ¶ˆã™\n",
    "collection = nltk.TextCollection(docs)\n",
    "terms = list(set(collection))\n",
    "nltk_vector = []\n",
    "for doc in docs:\n",
    "  tmp_vec = np.zeros(len(word2id))\n",
    "  for term in word2id.keys():\n",
    "    tmp_vec[word2id[term]] = collection.tf_idf(term, doc)\n",
    "  nltk_vector.append(list(tmp_vec))\n",
    "print(nltk_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "tEyOY2eQkRMc",
    "outputId": "0d93c47b-47ad-4e11-d3fd-62b19e24888e"
   },
   "outputs": [],
   "source": [
    "#gensim tf-idf ã‚ã¨ã§æ¶ˆã™\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "\n",
    "dictionary = corpora.Dictionary(docs)\n",
    "print('===å˜èª->idã®å¤‰æ›è¾æ›¸===')\n",
    "print(dictionary.token2id)\n",
    "print(word2id)\n",
    "\n",
    "corpus = list(map(dictionary.doc2bow, docs))\n",
    "test_model = models.TfidfModel(corpus)\n",
    "corpus_tfidf = test_model[corpus]\n",
    "\n",
    "print('===çµæœè¡¨ç¤º===')\n",
    "gensim_vector = []\n",
    "for doc in corpus_tfidf:\n",
    "  tmp_vec = [0] * len(word2id)\n",
    "  for word in doc:\n",
    "    key = dictionary[word[0]]\n",
    "    tmp_vec[word2id[key]] = word[1]\n",
    "  gensim_vector.append(tmp_vec)\n",
    "\n",
    "print(gensim_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMjo7F6ZKOW1"
   },
   "source": [
    "## Exercise 7\n",
    "\n",
    "æ§˜ã€…ãªå›½ã®Wikipediaã«ãŠã‘ã‚‹abstractã‚’å–ã‚Šå‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨æ„ã—ãŸ  \n",
    "https://drive.google.com/open?id=1i7tekPQRKaAwg-ze3kv5IsufMW13LkLo  \n",
    "ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†  \n",
    "\n",
    "Cosineé¡ä¼¼åº¦ã®è¨ˆç®—ã‚’è¡Œã„ã€Japanã«ä¼¼ã¦ã„ã‚‹å›½Top5ã‚’è¡¨ç¤ºã—ã¦ã¿ã‚ˆã†  \n",
    "å‰å‡¦ç†ã‚’è‡ªåˆ†ãªã‚Šã«å·¥å¤«ã™ã‚‹ã“ã¨  \n",
    "æ³¨ï¼‰é¡ä¼¼åº¦ã¯ã‚ã¾ã‚Šé«˜ããªã‚‰ãªãã¦ã‚‚è‰¯ã„  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "T1IbA30KKElT",
    "outputId": "755886e1-6ce4-4547-fcd9-83f8cd760601"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./nlp_country.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "A2ZqrWJhBAO2",
    "outputId": "411c6f83-dfa4-4751-b973-1cc1d27e2a9b"
   },
   "outputs": [],
   "source": [
    "df.iloc[0][\"Abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpQzg57nSAT2"
   },
   "outputs": [],
   "source": [
    "# å¾Œã§æ¶ˆã™\n",
    "def preprocessing_text(text):\n",
    "  def cleaning_text(text):\n",
    "    # @ã®å‰Šé™¤\n",
    "    pattern1 = '@|%'\n",
    "    text = re.sub(pattern1, '', text)    \n",
    "    pattern2 = '\\[[0-9 ]*\\]'\n",
    "    text = re.sub(pattern2, '', text)    \n",
    "    # <b>ã‚¿ã‚°ã®å‰Šé™¤\n",
    "    pattern3 = '\\([a-z ]*\\)'\n",
    "    text = re.sub(pattern3, '', text)    \n",
    "    pattern4 = '[0-9]'\n",
    "    text = re.sub(pattern4, '', text)\n",
    "    return text\n",
    "  \n",
    "  def tokenize_text(text):\n",
    "    text = re.sub('[.,]', '', text)\n",
    "    return text.split()\n",
    "\n",
    "  def lemmatize_word(word):\n",
    "    # make words lower  example: Python =>python\n",
    "    word=word.lower()\n",
    "    \n",
    "    # lemmatize  example: cooked=>cook\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "      return lemma\n",
    "    \n",
    "  text = cleaning_text(text)\n",
    "  tokens = tokenize_text(text)\n",
    "  tokens = [lemmatize_word(word) for word in tokens]\n",
    "  tokens = [remove_stopwords(word, en_stop) for word in tokens]\n",
    "  tokens = [word for word in tokens if word is not None]\n",
    "  return tokens\n",
    "  \n",
    "docs = df[\"Abstract\"].values\n",
    "pp_docs = [preprocessing_text(text) for text in docs]\n",
    "tfidf_vector, word2id = tfidf_vectorizer(pp_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "hNzPIvaxPOv5",
    "outputId": "843e5418-5a17-4a1e-86ea-fc8e5e7c7984"
   },
   "outputs": [],
   "source": [
    "word2id.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "_p73OT5sPs9y",
    "outputId": "39e8babf-2332-423b-f0d5-343856d826d3"
   },
   "outputs": [],
   "source": [
    "def calc_cosine(vector, vector_list):\n",
    "  result = {}\n",
    "  for i, x in enumerate(vector_list):\n",
    "    result[i] = cosine_similarity(vector, vector_list[i])\n",
    "    \n",
    "  return result\n",
    "\n",
    "print(\"tfidf\")\n",
    "res = calc_cosine(tfidf_vector[0],tfidf_vector)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "RMGEF5UJUZSz",
    "outputId": "f311182a-318b-4dae-bb89-b58693a0d2ec"
   },
   "outputs": [],
   "source": [
    "sorted(res.items(), key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OWm8pnAMQH-"
   },
   "source": [
    "## Option 3\n",
    "\n",
    "### Word2Vec & Doc2Vec\n",
    "\n",
    "Word2Vecã‚„Doc2Vecã§ã¯å˜èªã®æ„å‘³ã‚’æ‰ãˆã‚‰ã‚Œã¦ã„ã‚‹ã‹ã®ã‚ˆã†ãªæ¼”ç®—ãŒå‡ºæ¥ã‚‹  \n",
    "King - Man + Woman = Queen ãªã©  \n",
    "è©³ç´°ã¯è¬›ç¾©ã‚¹ãƒ©ã‚¤ãƒ‰ã¸   \n",
    "\n",
    "å­¦ç¿’æ¸ˆã¿ã®word2vecãŒgithub( https://github.com/Kyubyong/wordvectors )ã«ä¸ŠãŒã£ã¦ã„ã‚‹ã®ã§  \n",
    "æ—¥æœ¬ã¨å„å›½ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¦ã¿ã‚ˆã†  \n",
    "è¶³ã—ç®—ã‚„å¼•ãç®—ãŒå‡ºæ¥ã‚‹ã®ã§ãã‚Œã‚‚è©¦ã—ã¦ã¿ã‚ˆã†  \n",
    "\n",
    "å‚è€ƒ : \"BOKU\"ã®ITãªæ—¥å¸¸ (https://arakan-pgm-ai.hatenablog.com/entry/2019/02/08/090000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWddZ1mZXFsv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Similarity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
